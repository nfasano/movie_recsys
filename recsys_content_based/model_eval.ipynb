{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Model evaluation\n",
    "\n",
    "Description: (a) Examine tuned LDA model topics for interpretability\n",
    "             (b) For given test cases, plot the distribution of topics for that movie\n",
    "             (c) For given test cases, find top N movies with the most similar topic distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import time\n",
    "import gradio as gr\n",
    "import pickle\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in tuned model and transformed document-topic matrix\n",
    "lda_main = pickle.load(open('model_building_out\\\\model_2023_08_16.sav', 'rb'))\n",
    "lda10 = pickle.load(open('model_building_out\\\\hyperparameter_tuning\\\\model_10_components.sav', 'rb'))\n",
    "lda20 = pickle.load(open('model_building_out\\\\hyperparameter_tuning\\\\model_20_components.sav', 'rb'))\n",
    "\n",
    "with open(\"data_preprocessing_out\\\\word_key.txt\", \"rb\") as f:\n",
    "    word_key = pickle.load(f)\n",
    "\n",
    "# read in movie database\n",
    "df = pd.read_csv(\"..\\\\dataset_spaces_upload.csv\", index_col=[0])\n",
    "\n",
    "# read in scipy sparse matrix\n",
    "X = sparse.load_npz(\"data_preprocessing_out\\\\X.npz\")\n",
    "with open(\"model_building_out\\\\Xtran.txt\", \"rb\") as f:\n",
    "    Xtran_main = pickle.load(f)\n",
    "\n",
    "Xtran10 = lda10.transform(X)\n",
    "Xtran20 = lda20.transform(X)\n",
    "\n",
    "n_movies = len(df)\n",
    "n_features = len(word_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_words(model, feature_names, n_top_words, n_components, title):\n",
    "    # output: plot of top n_top_words for each topic in the model\n",
    "    fig, axes = plt.subplots(\n",
    "        int(np.ceil(n_components / 5)),\n",
    "        5,\n",
    "        figsize=(30, 30 * n_components / 20),\n",
    "        sharex=True,\n",
    "    )\n",
    "    axes = axes.flatten()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_features_ind = topic.argsort()[: -n_top_words - 1 : -1]\n",
    "        top_features = [feature_names[i] for i in top_features_ind]\n",
    "        weights = topic[top_features_ind]\n",
    "\n",
    "        ax = axes[topic_idx]\n",
    "        ax.barh(top_features, weights, height=0.7)\n",
    "        ax.set_title(f\"Topic {topic_idx +1}\", fontdict={\"fontsize\": 30})\n",
    "        ax.invert_yaxis()\n",
    "        ax.tick_params(axis=\"both\", which=\"major\", labelsize=20)\n",
    "        for i in \"top right left\".split():\n",
    "            ax.spines[i].set_visible(False)\n",
    "        fig.suptitle(title, fontsize=40)\n",
    "\n",
    "    plt.subplots_adjust(top=0.90, bottom=0.05, wspace=0.90, hspace=0.3)\n",
    "    plt.show()\n",
    "\n",
    "plot_top_words(lda_main, word_key, n_top_words=20, n_components=20, title=\"Topics in LDA model\")\n",
    "# plot_top_words(lda20, word_key, n_top_words=20, n_components=20, title=\"Topics in LDA model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_words_selected_topics(\n",
    "    model, feature_names, n_top_words, n_components, title, select_topics\n",
    "):\n",
    "    # output: plot of top n_top_words for each topic in the model\n",
    "    fig, axes = plt.subplots(\n",
    "        1,\n",
    "        5,\n",
    "        figsize=(12, 5),\n",
    "        sharex=False,\n",
    "    )\n",
    "    axes = axes.flatten()\n",
    "    kk = -1\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        if topic_idx in select_topics:\n",
    "            kk = kk + 1\n",
    "            top_features_ind = topic.argsort()[: -n_top_words - 1 : -1]\n",
    "            top_features = [feature_names[i] for i in top_features_ind]\n",
    "            weights = topic[top_features_ind]\n",
    "\n",
    "            ax = axes[kk]\n",
    "            ax.barh(top_features, weights, height=0.7)\n",
    "            ax.set_title(f\"Topic {kk+1}\", fontdict={\"fontsize\": 14})\n",
    "            ax.invert_yaxis()\n",
    "            ax.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "            ax.set_xlabel(\"word count\", fontdict={\"fontsize\": 14})\n",
    "            for i in \"top right left\".split():\n",
    "                ax.spines[i].set_visible(False)\n",
    "            fig.suptitle(title, fontsize=18)\n",
    "\n",
    "    plt.subplots_adjust(top=0.90, bottom=0.05, wspace=0.90, hspace=0.3)\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "fig = plot_top_words_selected_topics(\n",
    "    lda_main, word_key, 20, 20, \"\", [0, 1, 2, 3, 5]\n",
    ")\n",
    "fig.tight_layout()\n",
    "# fig.figure.savefig('model_eval_out\\\\select_topics.png', dpi=450, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some test cases - will be used as examples in app\n",
    "n_components = 20\n",
    "\n",
    "plt.rcParams.update({\"font.size\": 14})\n",
    "tested_examples = [\n",
    "    [\"The Dark Knight\", \"7.1\", True],\n",
    "    [\"A Christmas Carol, 2020\", \"7.1\", True],\n",
    "    [\"Remember the Titans\", \"7.1\", True],\n",
    "]\n",
    "\n",
    "# visualize the topic distribution for tested_examples\n",
    "\n",
    "# plot distribution of topic weights\n",
    "\n",
    "label_str = [\"(a)\", \"(b)\", \"(c)\"]\n",
    "top_title = [4, 14, 2, 13, 5, 17]\n",
    "for j, ex in enumerate(tested_examples):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(12, 4), width_ratios=[2, 1, 1])\n",
    "    ax = ax.flatten()\n",
    "    jmovie = df[df[\"movie_title\"] == ex[0]].index[0]\n",
    "    prob_height = np.round(Xtran_main[jmovie, :].reshape(1, n_components), 3).reshape(-1)\n",
    "    arg_topic = np.flip(np.argsort(prob_height))\n",
    "    ax[0].bar(x=list(range(1, n_components + 1)), height=prob_height)\n",
    "    ax[0].set_ylim(0, np.max(prob_height) + 0.05)\n",
    "    ax[0].set_xlim(0.5, n_components + 0.5)\n",
    "    ax[0].set_ylabel(\"topic proportion\")\n",
    "    ax[0].set_xlabel(\"topic number\")\n",
    "    ax[0].set_title(ex[0])\n",
    "    ax[0].set_xticks(list(range(1, n_components + 1, 2)))\n",
    "    ax[0].text(1, np.max(prob_height) + 0.025, label_str[j], fontweight='bold')\n",
    "\n",
    "    kk = 0\n",
    "    for topic_idx, topic in enumerate(lda_main.components_):\n",
    "        if topic_idx in arg_topic[0:2]:\n",
    "            kk = kk + 1\n",
    "            top_features_ind = topic.argsort()[: -15 - 1 : -1]\n",
    "            top_features = [word_key[i] for i in top_features_ind]\n",
    "            weights = topic[top_features_ind]\n",
    "\n",
    "            ax[kk].barh(top_features, weights, height=0.7)\n",
    "            ax[kk].set_title(f\"Topic {top_title[kk-1 + j*2]}\", fontdict={\"fontsize\": 14})\n",
    "            ax[kk].invert_yaxis()\n",
    "            ax[kk].tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "            ax[kk].set_xlabel(\"word count\", fontdict={\"fontsize\": 14})\n",
    "\n",
    "            for i in \"top right left\".split():\n",
    "                ax[kk].spines[i].set_visible(False)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.figure.savefig(\n",
    "        \"model_eval_out\\\\\"\n",
    "        + ex[0].replace(\" \", \"_\").replace(\"-\", \"\").replace(\"'\", \"\").lower()\n",
    "        + \"_top_topics.png\",\n",
    "        dpi=450,\n",
    "        bbox_inches=\"tight\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Model prediction and ranking of recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_rec(movie_name, rating_min, is_adult, Xtran, num_rec=5):\n",
    "    # compute top 5 movie recommendations for the input movie and filters\n",
    "    # inputs:\n",
    "    #       movie_name: selected movie_name from radio\n",
    "    #       rating_min: filter out all movies with ratings less than rating_min\n",
    "    #       is_adult: if True then filter out adult titles\n",
    "    # ouputs:\n",
    "    #       df_in: dataframe with all the info on movie_name\n",
    "    #       df_out: dataframe with all the info on top 5 recommended movies\n",
    "\n",
    "    if not movie_name:\n",
    "        raise gr.Error(\"Please select a movie before clicking Recommend\")\n",
    "\n",
    "    jmovie = df[df[\"movie_title\"] == movie_name].index[0]\n",
    "    sim_in = Xtran[jmovie, :].reshape(1, Xtran.shape[1])\n",
    "\n",
    "    if \"NULL\" in df[\"imdb_link\"].iloc[jmovie]:\n",
    "        # input movie has no matching IMDb title\n",
    "        link_in = [\"N/A\"]\n",
    "        genre_in = [\"N/A\"]\n",
    "        rating_in = [\"N/A\"]\n",
    "    else:\n",
    "        # link_in = construct_markdown_link([df[\"imdb_link\"].iloc[jmovie]], [movie_name])\n",
    "        genre_in = [df[\"genre\"].iloc[jmovie]]\n",
    "        rating_in = [df[\"average_rating\"].iloc[jmovie]]\n",
    "\n",
    "    # construct input dataframe\n",
    "    df_in = pd.DataFrame(\n",
    "        {\n",
    "            \"Title\": [movie_name],\n",
    "            \"Year\": [df[\"movie_year\"].iloc[jmovie]],\n",
    "            \"IMDb Rating\": rating_in,\n",
    "            \"Genres\": genre_in,\n",
    "            # \"IMDb Link\": link_in,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # compute similarity between movie_name and all other movies in database\n",
    "    sim_movie = cosine_similarity(sim_in, Xtran).reshape((len(df),))\n",
    "\n",
    "    # sort dataframe by movie similarity in descending order\n",
    "    arg_sim_movie_ordered = np.flip(np.argsort(sim_movie))\n",
    "    df_sort = df.iloc[arg_sim_movie_ordered[1:]]\n",
    "\n",
    "    # fiter by rating_min and is_adult\n",
    "    df_sort = df_sort[df_sort[\"average_rating\"] >= float(rating_min)]\n",
    "    if is_adult:\n",
    "        df_sort = df_sort[df_sort[\"is_adult\"] == 0]\n",
    "\n",
    "    # raise error if less than num_Rec movies are left after filtering\n",
    "    if len(df_sort) < num_rec:\n",
    "        raise gr.Error(\n",
    "            \"Not enough movies met the filter criteria. Try reducing the minimum rating.\"\n",
    "        )\n",
    "\n",
    "    # construct output dataframe\n",
    "    movie_title = df_sort[\"movie_title\"].iloc[0:num_rec].tolist()\n",
    "    movie_year = df_sort[\"movie_year\"].iloc[0:num_rec].tolist()\n",
    "    rating = df_sort[\"average_rating\"].iloc[0:num_rec].tolist()\n",
    "    genre = df_sort[\"genre\"].iloc[0:num_rec].tolist()\n",
    "    # link = construct_markdown_link(df_sort[\"imdb_link\"].iloc[0:5].tolist(), movie_title)\n",
    "\n",
    "    df_out = pd.DataFrame(\n",
    "        {\n",
    "            \"Title\": movie_title,\n",
    "            \"Year\": movie_year,\n",
    "            \"IMDb Rating\": rating,\n",
    "            \"Genres\": genre,\n",
    "            # \"IMDb Link\": link,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return df_in, df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some test cases - will be used as examples in app\n",
    "plt.rcParams.update({\"font.size\": 14})\n",
    "tested_examples = [\n",
    "    [\"Barbie\", \"5\", True],\n",
    "    [\"Green Book\", \"6.9\", True],\n",
    "    [\"Finding Nemo\", \"6\", True],\n",
    "    [\"How to Train Your Dragon\", \"6.7\", True],\n",
    "    [\"Remember the Titans\", \"5\", True],\n",
    "    [\"Avengers: Endgame\", \"7.4\", True],\n",
    "]\n",
    "\n",
    "\n",
    "for ex in tested_examples:\n",
    "    df_in, df_out = movie_rec(ex[0], ex[1], ex[2], Xtran_main, num_rec=10)\n",
    "    # df_in2, df_out2 = movie_rec(ex[0], ex[1], ex[2], Xtran20)\n",
    "    print(df_in.to_markdown() + '\\n')\n",
    "    print(df_out.to_markdown() + '\\n')\n",
    "    # print(df_out2.to_markdown() + '\\n')\n",
    "    print('----------------------------------------------------------------------------------------\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys_movie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
