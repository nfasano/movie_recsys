{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape television script data from Springfield! Springfield!\n",
    "\n",
    "## Written by Nicholas Fasano\n",
    "## Created: 01/12/2022\n",
    "### Website: https://www.springfieldspringfield.co.uk/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in python packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTvShowLinks(tvShowLinks, titleShow, link, i):\n",
    "    numLinksPerPage = 18\n",
    "    \n",
    "    # load in webpage content\n",
    "    page = requests.get(link)\n",
    "    soup = BeautifulSoup(page.content,'lxml')\n",
    "\n",
    "    # find links to TV episode scripts and append them to lists\n",
    "    results = soup.find_all('a',attrs={'href':re.compile(\"/episode_scripts.php\")})\n",
    "    for j in range(len(results)):      \n",
    "        linkTemp = results[j]\n",
    "        tvShowLinks[i*numLinksPerPage+j] = 'https://www.springfieldspringfield.co.uk'+linkTemp['href']\n",
    "        titleShow[i*numLinksPerPage+j] = linkTemp.text\n",
    "\n",
    "def getTvEpisodeLinks(tvEpisodeLinks, titleEpisode, titleShowEp, titleShow, link, i):\n",
    "    # load in webpage content\n",
    "    page = requests.get(link)\n",
    "    soup = BeautifulSoup(page.content,'lxml')\n",
    "         \n",
    "    # find links to TV episode scripts and append them to lists\n",
    "    results = soup.find_all('a',attrs={'href':re.compile(\"view_episode_scripts.php\")})\n",
    "    \n",
    "    tvEpisodeLinksTemp = []\n",
    "    titleEpisodeTemp = []\n",
    "    titleShowEpTemp = []\n",
    "    for j in range(len(results)):      \n",
    "        linkTemp = results[j]\n",
    "        tvEpisodeLinksTemp.append('https://www.springfieldspringfield.co.uk/'+linkTemp['href'])\n",
    "        titleEpisodeTemp.append(linkTemp.text)\n",
    "        titleShowEpTemp.append(titleShow)\n",
    "    tvEpisodeLinks[i] = tvEpisodeLinksTemp\n",
    "    titleEpisode[i] = titleEpisodeTemp\n",
    "    titleShowEp[i] =  titleShowEpTemp \n",
    "    \n",
    "def getScriptText(scriptText,link,i):\n",
    "    page = requests.get(link)\n",
    "    soup = BeautifulSoup(page.content,'lxml')\n",
    "    results = soup.find_all('div',attrs={'class':re.compile(\"scrolling-script-container\")})\n",
    "    scriptText[i] = results[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping approach: 1) get titles for all shows in database\n",
    "#                    2) find epsiode titles for each of the shows\n",
    "#                    3) get script text for all episodes of each show\n",
    "tvPageLinks = []\n",
    "numPages = 328\n",
    "for j in range(numPages):\n",
    "    tvPageLinks.append('https://www.springfieldspringfield.co.uk/tv_show_episode_scripts.php?page='+str(j+1))\n",
    "    \n",
    "numTvShows = len(tvPageLinks)\n",
    "titleShow = ['None']*numTvShows*18\n",
    "tvShowLinks = ['None']*numTvShows*18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution Time = 30.62 sec\n"
     ]
    }
   ],
   "source": [
    "# Execution time: ~25seconds at 10 pages per iteration\n",
    "t0 = time.time()\n",
    "numPagesPerIteration = 10\n",
    "numIterations = int(np.ceil(numTvShows/numPagesPerIteration))\n",
    "for k in range(numIterations):\n",
    "    linkIndex = [k*numPagesPerIteration + r for r in range(numPagesPerIteration) if k*numPagesPerIteration + r < numTvShows]\n",
    "    with ThreadPoolExecutor(max_workers=11) as executor:\n",
    "        [executor.submit(getTvShowLinks, tvShowLinks, titleShow, tvPageLinks[i],i) for i in linkIndex]\n",
    "        \n",
    "t1 = time.time()\n",
    "print(\"Execution Time = %.2f sec\" % (t1-t0))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of television shows is 5566\n"
     ]
    }
   ],
   "source": [
    "# remove duplicated links and 'None' values\n",
    "tvShowLinksRed = []\n",
    "titleShowRed = []\n",
    "for i in range(len(tvShowLinks)):\n",
    "    if (tvShowLinks[i] not in tvShowLinksRed) and (tvShowLinks[i] != 'None'):\n",
    "        tvShowLinksRed.append(tvShowLinks[i])\n",
    "        titleShowRed.append(titleShow[i])\n",
    "        \n",
    "print('Total number of television shows is %d' % (len(tvShowLinksRed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct dataframe with show links and save to a .csv file\n",
    "dictTemp = {'TV Show Title':titleShowRed,'TV Show Link':tvShowLinksRed}\n",
    "df = pd.DataFrame(dictTemp)\n",
    "now = datetime.datetime.now()  \n",
    "df.to_csv('springfield_tvShowLinks_'+now.strftime(\"%Y_%m_%d_%Hhr_%Mmin_%Ssec\")+'.csv')   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get episode links for all TV shows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numTvShows = len(tvShowLinksRed)\n",
    "titleEpisode = [[]]*numTvShows\n",
    "titleShowEp = [[]]*numTvShows\n",
    "tvEpisodeLinks = [[]]*numTvShows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.9 Percent completed (Total Time = 0.8 min)\n",
      "19.7 Percent completed (Total Time = 1.6 min)\n",
      "29.6 Percent completed (Total Time = 2.4 min)\n",
      "39.5 Percent completed (Total Time = 3.2 min)\n",
      "49.4 Percent completed (Total Time = 4.0 min)\n",
      "59.2 Percent completed (Total Time = 4.8 min)\n",
      "69.1 Percent completed (Total Time = 5.5 min)\n",
      "79.0 Percent completed (Total Time = 6.3 min)\n",
      "88.9 Percent completed (Total Time = 7.1 min)\n",
      "98.7 Percent completed (Total Time = 7.9 min)\n"
     ]
    }
   ],
   "source": [
    "# Execution time: ~7-8 minutes at 10 pages per iteration\n",
    "t0 = time.time()\n",
    "numPagesPerIteration = 10\n",
    "numIterations = int(np.ceil(numTvShows/numPagesPerIteration))\n",
    "for k in range(numIterations):\n",
    "    linkIndex = [k*numPagesPerIteration + r for r in range(numPagesPerIteration) if k*numPagesPerIteration + r < numTvShows]\n",
    "    with ThreadPoolExecutor(max_workers=11) as executor:\n",
    "        [executor.submit(getTvEpisodeLinks, tvEpisodeLinks, titleEpisode, titleShowEp, titleShowRed[i], tvShowLinksRed[i], i) for i in linkIndex]\n",
    "    if((k+1)%np.floor(numIterations/10) == 0):        \n",
    "        t1 = time.time()\n",
    "        print(\"%.1f Percent completed (Total Time = %.1f min)\" % (100*(k+1)/numIterations,(t1-t0)/60))\n",
    "        \n",
    "# unwrap lists of lists\n",
    "titleEpisode = [item for sublist in titleEpisode for item in sublist]\n",
    "titleShowEp = [item for sublist in titleShowEp for item in sublist]\n",
    "tvEpisodeLinks = [item for sublist in tvEpisodeLinks for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of television script links extracted was 132722\n"
     ]
    }
   ],
   "source": [
    "# remove duplicated links and 'None' values (execution time: ~2minutes)\n",
    "tvEpisodeLinksRed = []\n",
    "titleEpisodeRed = []\n",
    "titleShowEpRed = []\n",
    "for i in range(len(tvEpisodeLinks)):\n",
    "    if (tvEpisodeLinks[i] not in tvEpisodeLinksRed) and (tvEpisodeLinks[i] != 'None'):\n",
    "        tvEpisodeLinksRed.append(tvEpisodeLinks[i])\n",
    "        titleEpisodeRed.append(titleEpisode[i])\n",
    "        titleShowEpRed.append(titleShowEp[i])\n",
    "        \n",
    "print('Total number of television script links extracted was %d' % (len(tvEpisodeLinksRed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a pandas dataframe and save the file to a .csv file\n",
    "dicttemp = {'TV Show':titleShowEpRed,'TV Episode Name':titleEpisodeRed,'TV Episode Script Link':tvEpisodeLinksRed}\n",
    "df = pd.DataFrame(dicttemp)\n",
    "\n",
    "now = datetime.datetime.now()  \n",
    "df.to_csv('springfield_tvEpisodeLinks_'+now.strftime(\"%Y_%m_%d_%Hhr_%Mmin_%Ssec\")+'.csv')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "numTvEpisodes = len(tvEpisodeLinksRed)\n",
    "scriptText = ['None']*numTvEpisodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally, get the script text using these links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0 Percent completed (Total Time = 23 min)\n",
      "20.0 Percent completed (Total Time = 47 min)\n",
      "30.0 Percent completed (Total Time = 70 min)\n",
      "40.0 Percent completed (Total Time = 94 min)\n",
      "50.0 Percent completed (Total Time = 117 min)\n",
      "60.0 Percent completed (Total Time = 141 min)\n",
      "70.0 Percent completed (Total Time = 165 min)\n",
      "80.0 Percent completed (Total Time = 188 min)\n",
      "90.0 Percent completed (Total Time = 212 min)\n",
      "100.0 Percent completed (Total Time = 235 min)\n"
     ]
    }
   ],
   "source": [
    "# get script data -- takes ~1.1second/article * 36,000articles = 10hours of data collection. \n",
    "#                 -- This can also benefit from parallelization as all links are independent\n",
    "# Execution time: ~4.5 hours at 10 pages per iteration\n",
    "numPagesPerIteration = 10\n",
    "numIterations = int(np.ceil(numTvEpisodes/numPagesPerIteration))\n",
    "t0 = time.time()\n",
    "for k in range(numIterations):\n",
    "    linkIndex = [k*numPagesPerIteration + r for r in range(numPagesPerIteration) if k*numPagesPerIteration + r < numTvEpisodes]\n",
    "    with ThreadPoolExecutor(max_workers=11) as executor:\n",
    "        [executor.submit(getScriptText, scriptText, tvEpisodeLinksRed[i], i) for i in linkIndex]\n",
    "    if((k+1)%np.floor(numIterations/10) == 0):        \n",
    "        t1 = time.time()\n",
    "        print(\"%.1f Percent completed (Total Time = %.0f min)\" % (100*(k+1)/numIterations,(t1-t0)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up text before saving to .csv file \n",
    "for j in range(numTvEpisodes):\n",
    "    scriptText[j] = scriptText[j].replace(\"\\n\", \" \")\n",
    "    scriptText[j] = scriptText[j].replace(\"\\r\", \" \")\n",
    "    scriptText[j] = scriptText[j].replace(\"\\'\", \"\")\n",
    "    scriptText[j] = re.sub(' +', ' ', scriptText[j]) # removes excess spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a pandas dataframe and save the file to a .csv file\n",
    "dicttemp = {'TV Show':titleShowEpRed,'TV Episode Name':titleEpisodeRed,'TV Episode Script Link':tvEpisodeLinksRed,'Script Text':scriptText}\n",
    "df = pd.DataFrame(dicttemp)\n",
    "now = datetime.datetime.now()\n",
    "df.to_csv('SpringField_tvScripts_'+now.strftime(\"%Y_%m_%d_%Hhr_%Mmin_%Ssec\")+'.csv')     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "89440801d01f3d0d29046faa142b0848e8e5c5dee4c0149c8a8f825a956a2cd0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
