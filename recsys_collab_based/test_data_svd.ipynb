{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "import scipy as sp\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import line_profiler\n",
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create numpy array\n",
    "R = np.array(\n",
    "    [\n",
    "        [1, -1, 1, -1, 1, -1],\n",
    "        [1, 1, 0, -1, -1, -1],\n",
    "        [0, 1, 1, -1, -1, 0],\n",
    "        [-1, -1, -1, 1, 1, 1],\n",
    "        [-1, 0, -1, 1, 1, 1],\n",
    "    ],\n",
    "    dtype=float,\n",
    ")\n",
    "ij_missing = R == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "num_users = 5\n",
    "num_items = 6\n",
    "num_movies = num_items\n",
    "Rs = sps.coo_array(R)\n",
    "Rsc = Rs.tocsc()\n",
    "Rsr = Rs.tocsr()\n",
    "\n",
    "#\n",
    "nnz_entries_per_col = np.diff(Rsc.indptr)\n",
    "nnz_entries_per_row = np.diff(Rsr.indptr)\n",
    "\n",
    "nonzero_rows = Rsc.nonzero()[0]\n",
    "nonzero_cols = Rsc.nonzero()[1]\n",
    "\n",
    "# find mean of each row and column\n",
    "meanCol = Rsc.mean(axis=0) * num_users / nnz_entries_per_col\n",
    "meanRow = Rsc.mean(axis=1) * num_items / nnz_entries_per_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.5881  0.43   -0.43   -0.2095]\n",
      "\n",
      "[ 0.8826  0.6677 -0.6677 -0.5092]\n",
      "\n",
      "[ 0.9873  0.8008 -0.8008 -0.6995]\n",
      "\n",
      "[ 1.0188  0.8772 -0.8772 -0.8156]\n",
      "\n",
      "[ 1.0236  0.9226 -0.9226 -0.8862]\n",
      "\n",
      "[ 1.0201  0.9503 -0.9503 -0.9295]\n",
      "\n",
      "[ 1.0151  0.9678 -0.9678 -0.9562]\n",
      "\n",
      "[ 1.0107  0.979  -0.979  -0.9727]\n",
      "\n",
      "[ 1.0073  0.9862 -0.9862 -0.983 ]\n",
      "\n",
      "[ 1.0049  0.9909 -0.9909 -0.9894]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# implement svd algorithm using scipy.sparse.svd\n",
    "# This approach requires a dense matrix since each iteration\n",
    "# fills in the missing values with the latest prediction\n",
    "# Can avoid dense matrix if only one iteration is performed and\n",
    "# no initial guess is given, but that will likely not converge\n",
    "#\n",
    "\n",
    "# first fill in missing elements with row (user) mean\n",
    "# Note: for this example, the mean centering did not\n",
    "# affect prediction but led to faster convergence\n",
    "R_mean = R.copy()\n",
    "R_mean[1, 2] = meanRow[1]\n",
    "R_mean[2, 0] = meanRow[2]\n",
    "R_mean[2, 5] = meanRow[2]\n",
    "R_mean[4, 1] = meanRow[4]\n",
    "\n",
    "# iterate until convergence:\n",
    "for j in range(10):\n",
    "    # construct sparse matrix\n",
    "    Rsc = sps.coo_array(R_mean).tocsc()\n",
    "\n",
    "    # next run svd on the filled in matrix\n",
    "    U, sig, V = sps.linalg.svds(Rsc, k=2)\n",
    "\n",
    "    # compute new matrix\n",
    "    resulting_matrix = U @ np.diag(sig) @ V\n",
    "\n",
    "    # reset known ratings in resulting matrix\n",
    "    R_mean[ij_missing] = resulting_matrix[ij_missing]\n",
    "\n",
    "    print(np.round(resulting_matrix[ij_missing], 4))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given matrix\n",
    "R = np.array(\n",
    "    [\n",
    "        [1, -1, 1, -1, 1, -1],\n",
    "        [1, 1, 0, -1, -1, -1],\n",
    "        [0, 1, 1, -1, -1, 0],\n",
    "        [-1, -1, -1, 1, 1, 1],\n",
    "        [-1, 0, -1, 1, 1, 1],\n",
    "    ],\n",
    "    dtype=float,\n",
    ")\n",
    "\n",
    "Rs = sps.coo_array(R)\n",
    "Rsc = Rs.tocsc()\n",
    "Rsr = Rs.tocsr()\n",
    "\n",
    "nnz_row_per_col = np.diff(Rsc.indptr)\n",
    "nnz_col_per_row = np.diff(Rsr.indptr)\n",
    "\n",
    "nonzero_rows = Rsc.nonzero()[0]\n",
    "nonzero_cols = Rsc.nonzero()[1]\n",
    "\n",
    "# find mean of each row and column\n",
    "meanCol = Rsc.mean(axis=0)*num_users/nnz_row_per_col\n",
    "meanRow = Rsc.mean(axis=1)*num_items/nnz_col_per_row\n",
    "\n",
    "# find std of each row and column\n",
    "Rsc2 = Rsc**2\n",
    "stdCol = np.sqrt(Rsc2.mean(axis=0)*num_users/nnz_row_per_col - (Rsc.mean(axis=0)*num_users/nnz_row_per_col)**2)\n",
    "stdRow = np.sqrt(Rsc2.mean(axis=1)*num_items/nnz_col_per_row - (Rsc.mean(axis=1)*num_items/nnz_col_per_row)**2)\n",
    "\n",
    "# compute alternate arrays\n",
    "Rsc_mean = Rsc.copy()\n",
    "Rsc_mean.data = Rsc_mean.data - np.take(meanRow, Rsc_mean.indices)\n",
    "\n",
    "Rsr_mean = Rsc_mean.tocsr()\n",
    "\n",
    "\n",
    "\n",
    "# compute set of observed indices (i, j) = (rows, cols)\n",
    "irows, jcols, vals = sps.find(Rsc)\n",
    "num_nonzero_entries = len(vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00, -2.00000000e-01,  0.00000000e+00, -5.55111512e-17,\n",
       "        2.00000000e-01])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meanRow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd():\n",
    "    # implement matrix factorization with regularization\n",
    "    # use stochastic gradient descent for updates\n",
    "\n",
    "\n",
    "    k = 2  # number of latent factors\n",
    "    nbatch = 2\n",
    "    alpha = 0.005*num_nonzero_entries/nbatch  # learning rate\n",
    "    lam = 0.0  # regularization parameter\n",
    "    # inialize arrays\n",
    "\n",
    "    # U and V are full numpy arrays (dense)\n",
    "    U = np.random.random(size=(num_users, k)) * 2 - 1  # random numbers between [-1,1]\n",
    "    V = np.random.random(size=(num_movies, k)) * 2 - 1  # random numbers between [-1,1]\n",
    "    U_final = np.zeros(shape=U.shape)\n",
    "    V_final = np.zeros(shape=V.shape)\n",
    "\n",
    "    # E is sparse error matrix\n",
    "    E = Rsc_mean.copy()\n",
    "    Et = Rsr_mean.copy()\n",
    "\n",
    "    tole = 1e-3\n",
    "    n_epochs = 1\n",
    "\n",
    "\n",
    "    Etemp = Rsc_mean.copy()\n",
    "    Etempt = Rsr_mean.copy()\n",
    "    for k_epoch in range(n_epochs):\n",
    "        u_old = 0\n",
    "        v_old = 0\n",
    "        for q in range(k):\n",
    "            u_new = np.dot(U[:, q], U[:, q])\n",
    "            v_new = np.dot(V[:, q], V[:, q])\n",
    "            num_iter = 0\n",
    "            while np.abs(u_new - u_old) > tole and np.abs(v_new - v_old) > tole:\n",
    "                num_iter += 1\n",
    "                u_old = u_new\n",
    "                v_old = v_new\n",
    "                U_old = U.copy()\n",
    "                V_old = V.copy()\n",
    "\n",
    "                random_shuffle = np.arange(num_nonzero_entries)\n",
    "                # random_shuffle = np.unique(np.random.randint(0,num_nonzero_entries,size=(nbatch,)))\n",
    "                np.random.shuffle(random_shuffle)  # shuffle in place\n",
    "\n",
    "                # Etemp.data = np.array([0]*len(Etemp.data))\n",
    "                # Etempt.data = np.array([0]*len(Etempt.data))\n",
    "\n",
    "                for ij in random_shuffle:\n",
    "                    i = irows[ij]\n",
    "                    j = jcols[ij]\n",
    "\n",
    "                    temp2 = np.dot(U_old[i, :], V_old[j, :])\n",
    "\n",
    "                    # using csc format to update xx\n",
    "                    ind_j0 = E.indptr[j]\n",
    "                    ind_j1 = E.indptr[j + 1]\n",
    "                    e_ind = E.indices[ind_j0:ind_j1]\n",
    "                    Etemp.data[ind_j0:ind_j1][e_ind == i] = temp2\n",
    "\n",
    "                    # using csr format to update xx\n",
    "                    ind_j0 = Et.indptr[i]\n",
    "                    ind_j1 = Et.indptr[i + 1]\n",
    "                    et_ind = Et.indices[ind_j0:ind_j1]\n",
    "                    Etempt.data[ind_j0:ind_j1][et_ind == j] = temp2\n",
    "\n",
    "                E.data = Rsc_mean.data - Etemp.data\n",
    "                Et.data = Rsr_mean.data - Etempt.data\n",
    "\n",
    "                # consider larger batches and doing matrix multiplication\n",
    "                for ij in random_shuffle:\n",
    "                    i = irows[ij]\n",
    "                    j = jcols[ij]\n",
    "\n",
    "                    # using csc format to update xx\n",
    "                    ind_j0 = E.indptr[j]\n",
    "                    ind_j1 = E.indptr[j + 1]\n",
    "                    e_ind = E.indices[ind_j0:ind_j1]\n",
    "                    e_dat = E.data[ind_j0:ind_j1]\n",
    "\n",
    "                    # using csr format to update xx\n",
    "                    ind_j0 = Et.indptr[i]\n",
    "                    ind_j1 = Et.indptr[i + 1]\n",
    "                    et_ind = Et.indices[ind_j0:ind_j1]\n",
    "                    et_dat = Et.data[ind_j0:ind_j1]\n",
    "\n",
    "                    U[i, q] = U_old[i, q] + alpha *  (\n",
    "                        np.dot(et_dat, V_old[et_ind, q]) - lam * U_old[i, q]\n",
    "                    )\n",
    "                    V[j, q] = V_old[j, q] + alpha * (\n",
    "                        np.dot(e_dat, U_old[e_ind, q]) - lam * V_old[j, q]\n",
    "                    )\n",
    "                u_new = np.dot(U[:, q], U[:, q])\n",
    "                v_new = np.dot(V[:, q], V[:, q])\n",
    "            # R2 = R2 - U[:,[q]] @ np.transpose(V[:,[q]])\n",
    "        U_final = U_final + U\n",
    "        V_final = V_final + V\n",
    "\n",
    "    U_final = U_final / n_epochs\n",
    "    V_final = V_final / n_epochs\n",
    "\n",
    "    Rpred = U_final @ V_final.T\n",
    "    for ii in range(5):\n",
    "        Rpred[:, ii] = Rpred[:, ii] + meanRow[ii]\n",
    "    # Rpred[Rpred > 0] = 1\n",
    "    # Rpred[Rpred < 0] = -1\n",
    "    print(Rpred[ij_missing])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.19563305  1.06272351 -1.04146598 -0.84639851]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-07 s\n",
      "\n",
      "Total time: 0.0334904 s\n",
      "File: C:\\Users\\Nick\\AppData\\Local\\Temp\\ipykernel_13948\\446836788.py\n",
      "Function: svd at line 1\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     1                                           def svd():\n",
      "     2                                               # implement matrix factorization with regularization\n",
      "     3                                               # use stochastic gradient descent for updates\n",
      "     4                                           \n",
      "     5                                           \n",
      "     6         1          9.0      9.0      0.0      k = 2  # number of latent factors\n",
      "     7         1          3.0      3.0      0.0      nbatch = 2\n",
      "     8         1         17.0     17.0      0.0      alpha = 0.005*num_nonzero_entries/nbatch  # learning rate\n",
      "     9         1          3.0      3.0      0.0      lam = 0.0  # regularization parameter\n",
      "    10                                               # inialize arrays\n",
      "    11                                           \n",
      "    12                                               # U and V are full numpy arrays (dense)\n",
      "    13         1        620.0    620.0      0.2      U = np.random.random(size=(num_users, k)) * 2 - 1  # random numbers between [-1,1]\n",
      "    14         1        126.0    126.0      0.0      V = np.random.random(size=(num_movies, k)) * 2 - 1  # random numbers between [-1,1]\n",
      "    15         1         33.0     33.0      0.0      U_final = np.zeros(shape=U.shape)\n",
      "    16         1         12.0     12.0      0.0      V_final = np.zeros(shape=V.shape)\n",
      "    17                                           \n",
      "    18                                               # E is sparse error matrix\n",
      "    19         1       1997.0   1997.0      0.6      E = Rsc_mean.copy()\n",
      "    20         1       1218.0   1218.0      0.4      Et = Rsr_mean.copy()\n",
      "    21                                           \n",
      "    22         1          4.0      4.0      0.0      tole = 1e-3\n",
      "    23         1          7.0      7.0      0.0      n_epochs = 1\n",
      "    24                                           \n",
      "    25                                           \n",
      "    26         1       1259.0   1259.0      0.4      Etemp = Rsc_mean.copy()\n",
      "    27         1       1133.0   1133.0      0.3      Etempt = Rsr_mean.copy()\n",
      "    28         1         16.0     16.0      0.0      for k_epoch in range(n_epochs):\n",
      "    29         1          4.0      4.0      0.0          u_old = 0\n",
      "    30         1          3.0      3.0      0.0          v_old = 0\n",
      "    31         2         10.0      5.0      0.0          for q in range(k):\n",
      "    32         2       2121.0   1060.5      0.6              u_new = np.dot(U[:, q], U[:, q])\n",
      "    33         2        405.0    202.5      0.1              v_new = np.dot(V[:, q], V[:, q])\n",
      "    34         2         10.0      5.0      0.0              num_iter = 0\n",
      "    35        65       1407.0     21.6      0.4              while np.abs(u_new - u_old) > tole and np.abs(v_new - v_old) > tole:\n",
      "    36        65        191.0      2.9      0.1                  num_iter += 1\n",
      "    37        65        151.0      2.3      0.0                  u_old = u_new\n",
      "    38        65        134.0      2.1      0.0                  v_old = v_new\n",
      "    39        65        715.0     11.0      0.2                  U_old = U.copy()\n",
      "    40        65        379.0      5.8      0.1                  V_old = V.copy()\n",
      "    41                                           \n",
      "    42        65       1352.0     20.8      0.4                  random_shuffle = np.arange(num_nonzero_entries)\n",
      "    43                                                           # random_shuffle = np.unique(np.random.randint(0,num_nonzero_entries,size=(nbatch,)))\n",
      "    44        65       1718.0     26.4      0.5                  np.random.shuffle(random_shuffle)  # shuffle in place\n",
      "    45                                           \n",
      "    46                                                           # Etemp.data = np.array([0]*len(Etemp.data))\n",
      "    47                                                           # Etempt.data = np.array([0]*len(Etempt.data))\n",
      "    48                                           \n",
      "    49      1690       4530.0      2.7      1.4                  for ij in random_shuffle:\n",
      "    50      1690       5372.0      3.2      1.6                      i = irows[ij]\n",
      "    51      1690       5078.0      3.0      1.5                      j = jcols[ij]\n",
      "    52                                           \n",
      "    53      1690      32266.0     19.1      9.6                      temp2 = np.dot(U_old[i, :], V_old[j, :])\n",
      "    54                                           \n",
      "    55                                                               # using csc format to update xx\n",
      "    56      1690       5937.0      3.5      1.8                      ind_j0 = E.indptr[j]\n",
      "    57      1690       6224.0      3.7      1.9                      ind_j1 = E.indptr[j + 1]\n",
      "    58      1690       6670.0      3.9      2.0                      e_ind = E.indices[ind_j0:ind_j1]\n",
      "    59      1690      26158.0     15.5      7.8                      Etemp.data[ind_j0:ind_j1][e_ind == i] = temp2\n",
      "    60                                           \n",
      "    61                                                               # using csr format to update xx\n",
      "    62      1690       5867.0      3.5      1.8                      ind_j0 = Et.indptr[i]\n",
      "    63      1690       6387.0      3.8      1.9                      ind_j1 = Et.indptr[i + 1]\n",
      "    64      1690       6691.0      4.0      2.0                      et_ind = Et.indices[ind_j0:ind_j1]\n",
      "    65      1690      24963.0     14.8      7.5                      Etempt.data[ind_j0:ind_j1][et_ind == j] = temp2\n",
      "    66                                           \n",
      "    67        65        619.0      9.5      0.2                  E.data = Rsc_mean.data - Etemp.data\n",
      "    68        65        493.0      7.6      0.1                  Et.data = Rsr_mean.data - Etempt.data\n",
      "    69                                           \n",
      "    70                                                           # consider larger batches and doing matrix multiplication\n",
      "    71      1690       4906.0      2.9      1.5                  for ij in random_shuffle:\n",
      "    72      1690       5786.0      3.4      1.7                      i = irows[ij]\n",
      "    73      1690       5340.0      3.2      1.6                      j = jcols[ij]\n",
      "    74                                           \n",
      "    75                                                               # using csc format to update xx\n",
      "    76      1690       5543.0      3.3      1.7                      ind_j0 = E.indptr[j]\n",
      "    77      1690       6218.0      3.7      1.9                      ind_j1 = E.indptr[j + 1]\n",
      "    78      1690       7080.0      4.2      2.1                      e_ind = E.indices[ind_j0:ind_j1]\n",
      "    79      1690       6545.0      3.9      2.0                      e_dat = E.data[ind_j0:ind_j1]\n",
      "    80                                           \n",
      "    81                                                               # using csr format to update xx\n",
      "    82      1690       5507.0      3.3      1.6                      ind_j0 = Et.indptr[i]\n",
      "    83      1690       6159.0      3.6      1.8                      ind_j1 = Et.indptr[i + 1]\n",
      "    84      1690       6677.0      4.0      2.0                      et_ind = Et.indices[ind_j0:ind_j1]\n",
      "    85      1690       6517.0      3.9      1.9                      et_dat = Et.data[ind_j0:ind_j1]\n",
      "    86                                           \n",
      "    87      1690       8444.0      5.0      2.5                      U[i, q] = U_old[i, q] + alpha *  (\n",
      "    88      1690      48379.0     28.6     14.4                          np.dot(et_dat, V_old[et_ind, q]) - lam * U_old[i, q]\n",
      "    89                                                               )\n",
      "    90      1690       8056.0      4.8      2.4                      V[j, q] = V_old[j, q] + alpha * (\n",
      "    91      1690      44826.0     26.5     13.4                          np.dot(e_dat, U_old[e_ind, q]) - lam * V_old[j, q]\n",
      "    92                                                               )\n",
      "    93        65       1240.0     19.1      0.4                  u_new = np.dot(U[:, q], U[:, q])\n",
      "    94        65       1125.0     17.3      0.3                  v_new = np.dot(V[:, q], V[:, q])\n",
      "    95                                                       # R2 = R2 - U[:,[q]] @ np.transpose(V[:,[q]])\n",
      "    96         1         24.0     24.0      0.0          U_final = U_final + U\n",
      "    97         1         10.0     10.0      0.0          V_final = V_final + V\n",
      "    98                                           \n",
      "    99         1         84.0     84.0      0.0      U_final = U_final / n_epochs\n",
      "   100         1         21.0     21.0      0.0      V_final = V_final / n_epochs\n",
      "   101                                           \n",
      "   102         1        277.0    277.0      0.1      Rpred = U_final @ V_final.T\n",
      "   103         5         44.0      8.8      0.0      for ii in range(5):\n",
      "   104         5        117.0     23.4      0.0          Rpred[:, ii] = Rpred[:, ii] + meanRow[ii]\n",
      "   105                                               # Rpred[Rpred > 0] = 1\n",
      "   106                                               # Rpred[Rpred < 0] = -1\n",
      "   107         1       3667.0   3667.0      1.1      print(Rpred[ij_missing])"
     ]
    }
   ],
   "source": [
    "%lprun -f svd svd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[269], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m ind_j0 \u001b[39m=\u001b[39m E\u001b[39m.\u001b[39mindptr[j]\n\u001b[0;32m     14\u001b[0m ind_j1 \u001b[39m=\u001b[39m E\u001b[39m.\u001b[39mindptr[j \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[1;32m---> 15\u001b[0m e_ind \u001b[39m=\u001b[39m E\u001b[39m.\u001b[39;49mindices[ind_j0:ind_j1]\n\u001b[0;32m     16\u001b[0m Etemp\u001b[39m.\u001b[39mdata[ind_j0:ind_j1][e_ind \u001b[39m==\u001b[39m i] \u001b[39m=\u001b[39m temp2\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "# random_shuffle = np.arange(len(jcols))\n",
    "# np.random.shuffle(random_shuffle)  # shuffle in place\n",
    "\n",
    "# for ij in random_shuffle[0:5]:\n",
    "# i = irows[ij]\n",
    "# j = jcols[ij]\n",
    "\n",
    "i = irows[random_shuffle[0:5]]\n",
    "j = jcols[random_shuffle[0:5]]\n",
    "temp2 = np.sum(U_old[i, :]*V_old[j, :],axis=1)\n",
    "\n",
    "# using csc format to update xx\n",
    "ind_j0 = E.indptr[j]\n",
    "ind_j1 = E.indptr[j + 1]\n",
    "e_ind = E.indices[ind_j0:ind_j1]\n",
    "Etemp.data[ind_j0:ind_j1][e_ind == i] = temp2\n",
    "\n",
    "# # using csr format to update xx\n",
    "# ind_j0 = Et.indptr[i]\n",
    "# ind_j1 = Et.indptr[i + 1]\n",
    "# et_ind = Et.indices[ind_j0:ind_j1]\n",
    "# Etempt.data[ind_j0:ind_j1][et_ind == j] = temp2\n",
    "\n",
    "# E.data = Rsc_mean.data - Etemp.data\n",
    "# Et.data = Rsr_mean.data - Etempt.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17  0 12 17  8]\n",
      "[22  4 17 22 12]\n"
     ]
    }
   ],
   "source": [
    "ind_j0 = E.indptr[j]\n",
    "ind_j1 = E.indptr[j + 1]\n",
    "print(ind_j0)\n",
    "print(ind_j1)\n",
    "\n",
    "e_ind = E.indices[np.r_[tuple(slice(s, e) for s, e in zip(ind_j0,ind_j1))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 0, 1, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 2, 3,\n",
       "       4])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Etemp.data[ind_j0:ind_j1][e_ind == i] = temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.34729925, -1.01195332, -0.94655799,  0.9668216 ,  0.38105861,\n",
       "        0.75576971,  1.10648956, -1.15245143, -1.22819195, -0.79312914,\n",
       "       -0.80052277, -0.99253231,  0.85586837,  1.06158417,  0.34729925,\n",
       "       -1.01195332, -0.94655799,  0.9668216 ,  0.38105861,  0.85449777,\n",
       "        1.146598  , -0.9960005 , -1.19258012])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Etemp.data[np.r_[tuple(slice(s, e) for s, e in zip(ind_j0,ind_j1))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 0, 1, 3, 4, 0, 1, 2, 3, 4, 0, 1, 2, 3, 4, 0, 2, 3,\n",
       "       4])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 3, 4, 2])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 3, 4, 5])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., -1.,  1., -1.,  1., -1.],\n",
       "       [ 1.,  1.,  0., -1., -1., -1.],\n",
       "       [ 0.,  1.,  1., -1., -1.,  0.],\n",
       "       [-1., -1., -1.,  1.,  1.,  1.],\n",
       "       [-1.,  0., -1.,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.00018366039756939623\n",
    "\n",
    "temp = Rsc.copy()\n",
    "# temp.data = np.zeros(shape=temp.data.shape)\n",
    "\n",
    "# temp.data\n",
    "temp.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_sparse_col_array(R,row,col):\n",
    "    # returns array([], dtype=float64) if R[row,col] is missing \n",
    "    ind_j0 = R.indptr[col]\n",
    "    ind_j1 = R.indptr[col+1]\n",
    "    bb = R.indices[ind_j0:ind_j1]\n",
    "    cc = R.data[ind_j0:ind_j1]     \n",
    "    return cc[bb == row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_sparse_col_array(Rsc,0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_j0 = Rsc.indptr[0]\n",
    "ind_j1 = Rsc.indptr[0+1]\n",
    "bb = Rsc.indices[ind_j0:ind_j1]\n",
    "Rsc.data[ind_j0:ind_j1][bb == 0] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5., -1.,  1., -1.,  1., -1.],\n",
       "       [ 2.,  1.,  0., -1., -1., -1.],\n",
       "       [ 0.,  1.,  1., -1., -1.,  0.],\n",
       "       [ 2., -1., -1.,  1.,  1.,  1.],\n",
       "       [ 2.,  0., -1.,  1.,  1.,  1.]])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rsc.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement SVD using SurPRISE library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "\n",
    "# Creation of the dataframe. Column names are irrelevant.\n",
    "ratings_dict = {\n",
    "    \"userID\": [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4],\n",
    "    \"itemID\": [0, 1, 2, 3, 4, 5, 0, 1, 3, 4, 5, 1, 2, 3, 4, 0, 1, 2, 3, 4, 5, 0, 2, 3, 4, 5],\n",
    "    \"rating\": [1,-1, 1,-1, 1,-1, 1, 1,-1,-1,-1, 1, 1,-1,-1,-1,-1,-1, 1, 1, 1,-1,-1, 1, 1, 1],\n",
    "}\n",
    "df = pd.DataFrame(ratings_dict)\n",
    "\n",
    "# A reader is still needed but only the rating_scale param is requiered.\n",
    "reader = Reader(rating_scale=(-1, 1))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data = Dataset.load_from_df(df[[\"userID\", \"itemID\", \"rating\"]], reader)\n",
    "\n",
    "# We'll use the famous SVD algorithm.\n",
    "algo = SVD()\n",
    "\n",
    "# Run 5-fold cross-validation and print results\n",
    "# cross_validate(algo, data, measures=[\"RMSE\", \"MAE\"], cv=5, verbose=True)\n",
    "\n",
    "# Then predict ratings for all pairs (u, i) that are NOT in the training set.\n",
    "trainset = data.build_full_trainset()\n",
    "algo.fit(trainset)\n",
    "testset = trainset.build_anti_testset()\n",
    "predictions = algo.test(testset)\n",
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys_movie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
